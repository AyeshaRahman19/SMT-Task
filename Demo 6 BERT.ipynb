{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70398424-c8b1-4179-ad9e-a62542d224dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.8/10.0 MB 2.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/10.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.1/10.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.4/10.0 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.7/10.0 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.9/10.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.7/10.0 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.0/10.0 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.0/10.0 MB 1.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.3/10.0 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.6/10.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/10.0 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/10.0 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.1 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Ayesha\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Ayesha\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb154fcc-4a14-437e-a2bb-daef1440bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c84346-2557-489e-9a3f-c739b63f5f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ayesha\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a952a-e334-40d4-bd2b-240dd0ffcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['sentence1'] = train_df['premise'].apply(preprocess_text)\n",
    "train_df['sentence2'] = train_df['hypothesis'].apply(preprocess_text)\n",
    "\n",
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "X = encode_texts(train_df['sentence1'] + \" \" + train_df['sentence2'])\n",
    "y = train_df['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X['input_ids'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load Pre-trained BERT Model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Compile BERT Model\n",
    "bert_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train BERT Model\n",
    "bert_history = bert_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Evaluate BERT Model\n",
    "y_pred_bert = bert_model.predict(X_val).logits\n",
    "y_pred_classes_bert = np.argmax(y_pred_bert, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_classes_bert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_classes_bert))\n",
    "\n",
    "# AUC-ROC Curve for BERT\n",
    "y_pred_prob_bert = tf.nn.softmax(y_pred_bert).numpy()\n",
    "y_val_one_hot_bert = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_val_one_hot_bert[:, i], y_pred_prob_bert[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"BERT Model Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038262c-c678-47ad-a638-ae5b3e52c1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['sentence1'] = train_df['premise'].apply(preprocess_text)\n",
    "train_df['sentence2'] = train_df['hypothesis'].apply(preprocess_text)\n",
    "\n",
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "X = encode_texts(train_df['sentence1'] + \" \" + train_df['sentence2'])\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X['input_ids'].numpy(), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load Pre-trained BERT Model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Compile BERT Model\n",
    "bert_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train BERT Model\n",
    "bert_history = bert_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Evaluate BERT Model\n",
    "y_pred_bert = bert_model.predict(X_val).logits\n",
    "y_pred_classes_bert = np.argmax(y_pred_bert, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_classes_bert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_classes_bert))\n",
    "\n",
    "# AUC-ROC Curve for BERT\n",
    "y_pred_prob_bert = tf.nn.softmax(y_pred_bert).numpy()\n",
    "y_val_one_hot_bert = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_val_one_hot_bert[:, i], y_pred_prob_bert[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"BERT Model Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc3b5c4-9768-42c5-b13f-53907be51608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000002193D7B9940>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m TFBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Compile BERT Model\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m bert_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m),\n\u001b[0;32m     59\u001b[0m                    loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     60\u001b[0m                    metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Train BERT Model\u001b[39;00m\n\u001b[0;32m     63\u001b[0m bert_history \u001b[38;5;241m=\u001b[39m bert_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     64\u001b[0m     X_train, y_train,\n\u001b[0;32m     65\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m     66\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     67\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m\n\u001b[0;32m     68\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_tf_utils.py:1563\u001b[0m, in \u001b[0;36mTFPreTrainedModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;66;03m# This argument got renamed, we need to support both versions\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parent_args:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1564\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   1565\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m   1566\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mmetrics,\n\u001b[0;32m   1567\u001b[0m         loss_weights\u001b[38;5;241m=\u001b[39mloss_weights,\n\u001b[0;32m   1568\u001b[0m         weighted_metrics\u001b[38;5;241m=\u001b[39mweighted_metrics,\n\u001b[0;32m   1569\u001b[0m         run_eagerly\u001b[38;5;241m=\u001b[39mrun_eagerly,\n\u001b[0;32m   1570\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39msteps_per_execution,\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1572\u001b[0m     )\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1575\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   1576\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1583\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:335\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get(\n\u001b[0;32m    331\u001b[0m         config,\n\u001b[0;32m    332\u001b[0m         use_legacy_optimizer\u001b[38;5;241m=\u001b[39muse_legacy_optimizer,\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000002193D7B9940>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['sentence1'] = train_df['premise'].apply(preprocess_text)\n",
    "train_df['sentence2'] = train_df['hypothesis'].apply(preprocess_text)\n",
    "\n",
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "X = tokenizer(list(train_df['sentence1']), list(train_df['sentence2']),\n",
    "              padding=True, truncation=True, return_tensors=\"tf\", max_length=128)\n",
    "y = train_df['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X['input_ids'].numpy(), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load Pre-trained BERT Model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Compile BERT Model\n",
    "bert_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train BERT Model\n",
    "bert_history = bert_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Evaluate BERT Model\n",
    "y_pred_bert = bert_model.predict(X_val).logits\n",
    "y_pred_classes_bert = np.argmax(y_pred_bert, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_classes_bert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_classes_bert))\n",
    "\n",
    "# AUC-ROC Curve for BERT\n",
    "y_pred_prob_bert = tf.nn.softmax(y_pred_bert).numpy()\n",
    "y_val_one_hot_bert = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_val_one_hot_bert[:, i], y_pred_prob_bert[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"BERT Model Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c7098-1931-4a0f-9441-a4c5bd25ae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayesha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Ayesha\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ayesha\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "296/606 [=============>................] - ETA: 42:50 - loss: 1.1614 - accuracy: 0.3378"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['sentence1'] = train_df['premise'].apply(preprocess_text)\n",
    "train_df['sentence2'] = train_df['hypothesis'].apply(preprocess_text)\n",
    "\n",
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "X = tokenizer(list(train_df['sentence1']), list(train_df['sentence2']),\n",
    "              padding=True, truncation=True, return_tensors=\"tf\", max_length=128)\n",
    "y = train_df['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X['input_ids'].numpy(), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load Pre-trained BERT Model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Compile BERT Model\n",
    "bert_model.compile(optimizer='adam',\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train BERT Model\n",
    "bert_history = bert_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Evaluate BERT Model\n",
    "y_pred_bert = bert_model.predict(X_val).logits\n",
    "y_pred_classes_bert = np.argmax(y_pred_bert, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_classes_bert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_classes_bert))\n",
    "\n",
    "# AUC-ROC Curve for BERT\n",
    "y_pred_prob_bert = tf.nn.softmax(y_pred_bert).numpy()\n",
    "y_val_one_hot_bert = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_val_one_hot_bert[:, i], y_pred_prob_bert[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"BERT Model Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1a52-b366-4e5b-bf04-3cf6593d0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['sentence1'] = train_df['premise'].apply(preprocess_text)\n",
    "train_df['sentence2'] = train_df['hypothesis'].apply(preprocess_text)\n",
    "\n",
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "X = tokenizer(list(train_df['sentence1']), list(train_df['sentence2']),\n",
    "              padding=True, truncation=True, return_tensors=\"tf\", max_length=128)\n",
    "y = train_df['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X['input_ids'].numpy(), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load Pre-trained BERT Model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Hyperparameter tuning function\n",
    "def build_model(learning_rate):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [5e-5, 3e-5, 2e-5],\n",
    "    'batch_size': [8, 16, 32],\n",
    "    'epochs': [3, 4, 5]\n",
    "}\n",
    "\n",
    "best_params = {'learning_rate': 2e-5, 'batch_size': 16, 'epochs': 3}  # Placeholder for GridSearchCV result\n",
    "\n",
    "# Compile model with best parameters\n",
    "bert_model = build_model(best_params['learning_rate'])\n",
    "\n",
    "# Train BERT Model\n",
    "bert_history = bert_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size']\n",
    ")\n",
    "\n",
    "# Evaluate BERT Model\n",
    "y_pred_bert = bert_model.predict(X_val).logits\n",
    "y_pred_classes_bert = np.argmax(y_pred_bert, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_classes_bert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_classes_bert))\n",
    "\n",
    "# AUC-ROC Curve for BERT\n",
    "y_pred_prob_bert = tf.nn.softmax(y_pred_bert).numpy()\n",
    "y_val_one_hot_bert = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(3):\n",
    "    fpr, tpr, _ = roc_curve(y_val_one_hot_bert[:, i], y_pred_prob_bert[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"BERT Model Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f801d-4fcc-4893-8287-6fc18f12cf26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
